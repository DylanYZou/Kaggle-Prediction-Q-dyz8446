{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6ec7",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. This is the template you may use to submit your code and report for the prediction problems on Kaggle.\n",
    "\n",
    "2. You may modify the template if you deem fit, but it should have the information asked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.1) Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning steps taken to prepare your data for developing the model. This may include imputing missing values, dealing with outliers, combining levels of categorical variable(s), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94664bd",
   "metadata": {},
   "source": [
    "* Put your data cleaning/preparation code with comments here\n",
    "* The code should begin from reading the train data\n",
    "* The code should end when you obtain the data used to develop the model in A.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7078479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Data'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\Data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e143c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrix\n",
    "from pyearth import Earth\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, roc_curve, auc, precision_recall_curve, make_scorer,\n",
    "                             recall_score, accuracy_score, precision_score, confusion_matrix)\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split, KFold, StratifiedKFold,\n",
    "                                     GridSearchCV, ParameterGrid)\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import (BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, \n",
    "                              GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostRegressor, AdaBoostClassifier, \n",
    "                              VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools as it\n",
    "import xgboost as xgb\n",
    "import time as time\n",
    "import random\n",
    "from skimpy import clean_columns\n",
    "\n",
    "#Libraries for visualizing trees\n",
    "from sklearn.tree import export_graphviz \n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "51430c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.head()\n",
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19ab73",
   "metadata": {},
   "source": [
    "Dropping Categorical, but not the Nulls just yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "df6a3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_clean(data):\n",
    "    data = data.replace([np.inf], np.nan)\n",
    "    data = data.replace([-np.inf], np.nan)\n",
    "    \n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    data = data.drop(categorical_columns, axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_cleaned = function_clean(train)\n",
    "test_cleaned = function_clean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.2) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fff41",
   "metadata": {},
   "source": [
    "Mention any major insights you obtained from the data, which you used to develop the model. Please put your code or visualizations here if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "da91208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y       1.000000\n",
       "x146    0.378696\n",
       "x102    0.378436\n",
       "x014    0.364737\n",
       "x581    0.346549\n",
       "          ...   \n",
       "x465         NaN\n",
       "x518         NaN\n",
       "x594         NaN\n",
       "x643         NaN\n",
       "x703         NaN\n",
       "Name: y, Length: 756, dtype: float64"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = train_cleaned.corr().sort_values(by = 'y', ascending = False)\n",
    "corr_matrix['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf90456",
   "metadata": {},
   "source": [
    "Whilst we still had our null values and the potential unrepresented data in there, I wanted to use KNN to predict the null values, but realized this would be difficult with the faint correlations of the correlation matrix.\n",
    "\n",
    "I realize I could've use something like a PCA in the aim of something like this, or grouping certain variables via desicion trees into a single variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "cdbfb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nulls(df):\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    columns_to_drop = null_counts[null_counts > 50].index\n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "test_cleaner = drop_nulls(test_cleaned)\n",
    "train_cleaner = drop_nulls(train_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d4e3a",
   "metadata": {},
   "source": [
    "For the rest I just replaced with averages to finally get rid of all the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "860cc37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_avg(data):\n",
    "    for column in data.columns:\n",
    "        avg = data[column].mean()\n",
    "        data[column].fillna(avg, inplace=True)\n",
    "    return data\n",
    "\n",
    "train_avg = replace_avg(train_cleaner)\n",
    "test_avg = replace_avg(test_cleaner)\n",
    "test_avg.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "47f85015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x632', 'x182', 'x336', 'x274', 'x075', 'x573', 'x249', 'x178', 'x672', 'x120', 'x043', 'x546', 'x165', 'x588', 'x395', 'x228', 'x207', 'x544', 'x627', 'x760', 'x012', 'x136', 'x084', 'x679', 'x048', 'x500', 'x442', 'x009', 'x143', 'x393', 'x238', 'x329', 'x205', 'x267', 'x292', 'x386', 'x678', 'x351', 'x433', 'x050', 'x278', 'x660', 'x153', 'x719', 'x051', 'x313', 'x360', 'x186', 'x683', 'x762', 'x065', 'x314', 'x052', 'x071', 'x119', 'x705', 'x031', 'x141'}\n",
      "{'y'}\n"
     ]
    }
   ],
   "source": [
    "overlap1 = set(test_avg.columns) - set(train_avg.columns)\n",
    "overlap2 = set(train_avg.columns) - set(test_avg.columns)\n",
    "\n",
    "print(overlap1)\n",
    "print(overlap2)\n",
    "\n",
    "true_test = test_avg.drop(columns = overlap1)\n",
    "true_train = train_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48572d",
   "metadata": {},
   "source": [
    "I made sure to apply my data cleaning/analysis functions on the test just in case I needed the dataset to look at. overall, there was 618 columns for the train and 628 for the test, which suggests that the ladder half in the test data might have a different structure than the first half, but overall (only 10 columns lost), seem to be pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "f3107ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x761</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>26900000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.5707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>297281012</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>169000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>3320000000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>135000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>100474819</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>37000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>348000000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>6000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>109546590</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5375</td>\n",
       "      <td>3.948791e+09</td>\n",
       "      <td>24563.46</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>9.871977e+08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3303184.55</td>\n",
       "      <td>3154159.0</td>\n",
       "      <td>11900000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>15.10</td>\n",
       "      <td>1.3758</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>158603315</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7480</td>\n",
       "      <td>93.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>5376</td>\n",
       "      <td>9.279017e+10</td>\n",
       "      <td>21572.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>3.093006e+09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2649164.57</td>\n",
       "      <td>2934417.0</td>\n",
       "      <td>7220000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>558.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>36089167</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>23.6890</td>\n",
       "      <td>76.05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>5377</td>\n",
       "      <td>2.700359e+10</td>\n",
       "      <td>23061.73</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>3.857656e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1825306.07</td>\n",
       "      <td>2395841.0</td>\n",
       "      <td>3960000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>1786891</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3710</td>\n",
       "      <td>80.30</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>5378</td>\n",
       "      <td>4.351107e+10</td>\n",
       "      <td>5739.04</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.318517e+09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>144103.12</td>\n",
       "      <td>715173.0</td>\n",
       "      <td>4150000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>194000000000</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "      <td>24.6594</td>\n",
       "      <td>7.95</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>5379</td>\n",
       "      <td>3.972951e+09</td>\n",
       "      <td>3368.55</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.324317e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>471263.24</td>\n",
       "      <td>419675.0</td>\n",
       "      <td>42100000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5740000000000</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0195</td>\n",
       "      <td>19.07</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          x001      x002  x003     x004          x005  x006  \\\n",
       "0        0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1        1  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2        2  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3        3  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4        4  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "...    ...           ...       ...   ...      ...           ...   ...   \n",
       "5375  5375  3.948791e+09  24563.46  6.73  0.00035  9.871977e+08  0.43   \n",
       "5376  5376  9.279017e+10  21572.94  6.96  0.00120  3.093006e+09  0.30   \n",
       "5377  5377  2.700359e+10  23061.73  6.36  0.00065  3.857656e+09  0.35   \n",
       "5378  5378  4.351107e+10   5739.04  7.80  0.00065  1.318517e+09  0.29   \n",
       "5379  5379  3.972951e+09   3368.55  6.15  0.00000  1.324317e+09  0.00   \n",
       "\n",
       "             x007       x008                x010  ...    x754   x755    x756  \\\n",
       "0       266117.20   934577.0      26900000000000  ...    92.0   3.37  1.5707   \n",
       "1     11927742.92  1798051.0  169000000000000000  ...  1026.0   2.40  0.1173   \n",
       "2       774385.01   375738.0     135000000000000  ...   162.0   6.67  0.4582   \n",
       "3      6324375.16  1932094.0   37000000000000000  ...   817.0   7.40  0.3816   \n",
       "4       169860.29   474253.0       6000000000000  ...    62.0   1.14  0.0100   \n",
       "...           ...        ...                 ...  ...     ...    ...     ...   \n",
       "5375   3303184.55  3154159.0   11900000000000000  ...   685.0  15.10  1.3758   \n",
       "5376   2649164.57  2934417.0    7220000000000000  ...   558.0   4.38  0.2230   \n",
       "5377   1825306.07  2395841.0    3960000000000000  ...   650.0   1.87  0.1300   \n",
       "5378    144103.12   715173.0       4150000000000  ...    56.0   7.51  0.2719   \n",
       "5379    471263.24   419675.0      42100000000000  ...   141.0   6.29  0.4605   \n",
       "\n",
       "        x757           x758  x759  x761     x763    x764   y  \n",
       "0     0.0007      297281012  0.13     5   8.5127   14.28   5  \n",
       "1     0.1136  3320000000000  0.08     0   1.5700  160.12   1  \n",
       "2     0.0029      100474819  0.39     2   9.6800   25.06  11  \n",
       "3     0.0000   348000000000  0.25     1   4.5316  117.76   1  \n",
       "4     0.0005      109546590  0.11     1  16.2717    5.81   5  \n",
       "...      ...            ...   ...   ...      ...     ...  ..  \n",
       "5375  0.0000      158603315  0.05     0   2.7480   93.45   4  \n",
       "5376  0.0003       36089167  0.01     4  23.6890   76.05   8  \n",
       "5377  0.0057        1786891  0.53     0   4.3710   80.30  21  \n",
       "5378  0.0001   194000000000  0.29     2  24.6594    7.95  13  \n",
       "5379  0.0000  5740000000000  0.51     0   2.0195   19.07  28  \n",
       "\n",
       "[5380 rows x 618 columns]"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = train_avg.columns[train_avg.corr()['y'].isnull()]\n",
    "true_test = true_test.drop(columns = null)\n",
    "true_train = true_train.drop(columns = null)\n",
    "\n",
    "true_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "ca15ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x753</th>\n",
       "      <th>x754</th>\n",
       "      <th>x755</th>\n",
       "      <th>x756</th>\n",
       "      <th>x757</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x761</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>6.507826e+10</td>\n",
       "      <td>7882.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>1.712586e+09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>583617.74</td>\n",
       "      <td>862986.0</td>\n",
       "      <td>147000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131.17</td>\n",
       "      <td>202.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>90204869909</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>30.1213</td>\n",
       "      <td>27.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>3.122741e+09</td>\n",
       "      <td>4682.13</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.040914e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190000.65</td>\n",
       "      <td>688710.0</td>\n",
       "      <td>11300000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>110.80</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>37449565014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1282</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.888719e+10</td>\n",
       "      <td>7495.57</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>2.160400e+09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>351570.67</td>\n",
       "      <td>841523.0</td>\n",
       "      <td>41400000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.10</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>10847937619</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8513</td>\n",
       "      <td>21.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>7.727427e+10</td>\n",
       "      <td>4003.76</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>5.519591e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320216.05</td>\n",
       "      <td>466131.0</td>\n",
       "      <td>20800000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>158.21</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37200096</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0511</td>\n",
       "      <td>18.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>4.184868e+09</td>\n",
       "      <td>34874.72</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.046217e+09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3349978.53</td>\n",
       "      <td>3711028.0</td>\n",
       "      <td>21100000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.62</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.8737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16400000000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>149.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>3.217682e+09</td>\n",
       "      <td>2214.42</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.608841e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>520766.78</td>\n",
       "      <td>172141.0</td>\n",
       "      <td>38700000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>31446931515</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6431</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>3.042820e+10</td>\n",
       "      <td>14279.29</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00135</td>\n",
       "      <td>1.901762e+09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1634334.25</td>\n",
       "      <td>1420919.0</td>\n",
       "      <td>2330000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.70</td>\n",
       "      <td>474.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18200000000000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2</td>\n",
       "      <td>12.3538</td>\n",
       "      <td>68.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>8.556628e+09</td>\n",
       "      <td>7518.26</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>2.852209e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>559939.70</td>\n",
       "      <td>911940.0</td>\n",
       "      <td>122000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.75</td>\n",
       "      <td>209.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>551000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5226</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>7.384902e+10</td>\n",
       "      <td>2556.73</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>1.605414e+09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>186175.29</td>\n",
       "      <td>236336.0</td>\n",
       "      <td>2960000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.10</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>20500000000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>6</td>\n",
       "      <td>32.7632</td>\n",
       "      <td>10.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>1.245804e+10</td>\n",
       "      <td>1481.99</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.114510e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>148362.27</td>\n",
       "      <td>144983.0</td>\n",
       "      <td>1980000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>148.30</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5.21</td>\n",
       "      <td>1.2049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>121000000000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9617</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 617 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          x001      x002  x003     x004          x005  x006  \\\n",
       "0     5380  6.507826e+10   7882.15  6.82  0.00210  1.712586e+09  0.39   \n",
       "1     5381  3.122741e+09   4682.13  8.17  0.00010  1.040914e+09  0.00   \n",
       "2     5382  3.888719e+10   7495.57  7.15  0.00285  2.160400e+09  0.42   \n",
       "3     5383  7.727427e+10   4003.76  6.53  0.00165  5.519591e+09  0.00   \n",
       "4     5384  4.184868e+09  34874.72  6.39  0.00065  1.046217e+09  0.50   \n",
       "...    ...           ...       ...   ...      ...           ...   ...   \n",
       "4398  9778  3.217682e+09   2214.42  5.27  0.00010  1.608841e+09  0.00   \n",
       "4399  9779  3.042820e+10  14279.29  6.18  0.00135  1.901762e+09  0.33   \n",
       "4400  9780  8.556628e+09   7518.26  6.74  0.00005  2.852209e+09  0.00   \n",
       "4401  9781  7.384902e+10   2556.73  6.47  0.00140  1.605414e+09  0.25   \n",
       "4402  9782  1.245804e+10   1481.99  5.92  0.00000  3.114510e+09  0.00   \n",
       "\n",
       "            x007       x008               x010  ...    x753    x754   x755  \\\n",
       "0      583617.74   862986.0    147000000000000  ...  131.17   202.0   4.01   \n",
       "1      190000.65   688710.0     11300000000000  ...  110.80    62.0   2.94   \n",
       "2      351570.67   841523.0     41400000000000  ...  127.10   140.0   1.45   \n",
       "3      320216.05   466131.0     20800000000000  ...  158.21   119.0   2.90   \n",
       "4     3349978.53  3711028.0  21100000000000000  ...  129.62  1061.0  10.90   \n",
       "...          ...        ...                ...  ...     ...     ...    ...   \n",
       "4398   520766.78   172141.0     38700000000000  ...  129.00   135.0   2.30   \n",
       "4399  1634334.25  1420919.0   2330000000000000  ...  122.70   474.0   4.13   \n",
       "4400   559939.70   911940.0    122000000000000  ...  130.75   209.0   3.92   \n",
       "4401   186175.29   236336.0      2960000000000  ...  121.10    71.0   6.44   \n",
       "4402   148362.27   144983.0      1980000000000  ...  148.30    65.0   5.21   \n",
       "\n",
       "        x756    x757             x758  x759  x761     x763    x764  \n",
       "0     0.0380  0.0010      90204869909  0.26     5  30.1213   27.95  \n",
       "1     0.1866  0.0192      37449565014  0.02     1   2.1282   10.18  \n",
       "2     0.0100  0.0017      10847937619  0.83     1   7.8513   21.27  \n",
       "3     0.4636  0.0000         37200096  0.51     4   9.0511   18.38  \n",
       "4     2.8737  0.0001   16400000000000  0.12     1   2.6512  149.68  \n",
       "...      ...     ...              ...   ...   ...      ...     ...  \n",
       "4398  0.0771  0.0095      31446931515  0.74     0   1.6431   22.42  \n",
       "4399  0.2828  0.0000   18200000000000  0.42     2  12.3538   68.09  \n",
       "4400  0.2890  0.0010     551000000000  0.67     1   2.5226   29.27  \n",
       "4401  0.5227  0.0127   20500000000000  0.67     6  32.7632   10.22  \n",
       "4402  1.2049  0.0000  121000000000000  0.40     0   1.9617   12.18  \n",
       "\n",
       "[4403 rows x 617 columns]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "b2555130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            VIF\n",
      "id    10.903311\n",
      "x402   8.413305\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = true_train.corr()\n",
    "\n",
    "vif = pd.DataFrame(index=true_train.columns, columns=['VIF'])\n",
    "\n",
    "for var in true_train.columns:\n",
    "    mask = true_train.columns != var\n",
    "    r_squared = 1.0 - corr_matrix.loc[var, mask].pow(2).sum()\n",
    "    vif.loc[var, 'VIF'] = 1.0 / (1.0 - r_squared)\n",
    "    \n",
    "high_vif_variables = vif[vif['VIF'] > 3]\n",
    "print(high_vif_variables)\n",
    "\n",
    "#null = train_avg.columns[train_avg.corr()['y'].isnull()]\n",
    "#true_test = true_test.drop(columns = null)\n",
    "#true_train = true_train.drop(columns = null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f9d7a",
   "metadata": {},
   "source": [
    "Due to the severe lack of VIF variables, and the presumable high dimensionality of the data I was working with, I attempted to pivot towards developing a PCA in order to reduce the dimensionality and the variables drastically.\n",
    "\n",
    "I chose PCA because it is unsupervised seeing as it did not consider Y, unlike some other selection processes which consider proximity, etc etc. I was also having a lot of trouble selecting variables at this point so I decided to just start over as I wasn't sure if I was just cleaning significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "75629672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x102    5380\n",
       "x570    5380\n",
       "x687    5380\n",
       "x651    5380\n",
       "x631    5380\n",
       "        ... \n",
       "x394       0\n",
       "x391       0\n",
       "x390       0\n",
       "x002       0\n",
       "y          0\n",
       "Length: 616, dtype: int64"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true = true_test.drop(columns = ['id', 'x402'])\n",
    "train_true = true_train.drop(columns = ['id','x402'])\n",
    "\n",
    "logtrain = np.log(train_true)\n",
    "logtest = np.log(test_true)\n",
    "\n",
    "logtrain = function_clean(logtrain)\n",
    "logtest = function_clean(logtest)\n",
    "\n",
    "#logtrain = replace_avg(logtrain)\n",
    "#logtest = replace_avg(logtest)\n",
    "\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(test_clean_true)\n",
    "logtrain.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396f34c",
   "metadata": {},
   "source": [
    "I think I decided to log the data because some of the values seemed extreme; but also it had the other effect of giving infinite values which I had an excuse to now clean.\n",
    "\n",
    "I was also having some problems with dropna, so I just decided to make a function for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "8a8a5046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_nulls(df):\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    columns_to_drop = null_counts[null_counts > 20].index\n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "train_dropped = drop_nulls(logtrain)\n",
    "test_dropped = drop_nulls(logtest)\n",
    "\n",
    "train = replace_avg(train_dropped)\n",
    "test = replace_avg(test_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "c652e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap1 = set(test.columns) - set(train.columns)\n",
    "overlap2 = set(train.columns) - set(test.columns)\n",
    "\n",
    "_test = test.drop(columns = overlap1)\n",
    "_train = train.drop(columns = overlap2)\n",
    "_ytrain = train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76202c1c",
   "metadata": {},
   "source": [
    "I now have my training and test data, filtered down to only 357 columns but many more to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43d8af",
   "metadata": {},
   "source": [
    "## A.3) Feature selection/reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc78b0",
   "metadata": {},
   "source": [
    "Mention the steps for feature selection/reduction. Please put your code or visualizations here if needed.\n",
    "\n",
    "- I felt most comfortable with Neural Networks, so I used a PCA + Neural Ensemble Model to try and feature select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "dbcba7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import Bidirectional, MaxPooling2D \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "f46b0c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.27962705 0.16901551 0.11529849 0.0724644  0.04958262 0.03393412\n",
      " 0.02692434 0.01961699 0.01933426 0.01330721 0.0127878  0.01053347\n",
      " 0.00877735 0.00833204 0.00771909 0.00660525 0.00635235 0.00591934\n",
      " 0.00539327 0.00498733 0.00489137 0.00459015 0.00435828 0.00419988\n",
      " 0.0040785  0.0040049  0.00357149 0.00339706 0.003222   0.00308328\n",
      " 0.00296318 0.00293465 0.00284362 0.00277817 0.0026599  0.00262823\n",
      " 0.00245465 0.0023865  0.0023454  0.00227897 0.00216725 0.00214226\n",
      " 0.00213617 0.00208896 0.00197638 0.00193201 0.00181369 0.00179038\n",
      " 0.00169091 0.00161075 0.00155345 0.00149478 0.00144642 0.00142061\n",
      " 0.00139727 0.00134688 0.00130079 0.00129026 0.0012299  0.00118318\n",
      " 0.00114639 0.00110025 0.00106091 0.00096858 0.00093972 0.00090459\n",
      " 0.00088482 0.00083055 0.00080745 0.00077907 0.00070803 0.00067277\n",
      " 0.00066672 0.00064352 0.00061853 0.00060275 0.00057887 0.00056499\n",
      " 0.00051498]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(_train)\n",
    "X_test_scaled = scaler.transform(_test)\n",
    "\n",
    "pca = PCA(n_components=.99)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "39495f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 79)"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "447e8d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4403, 79)"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a671c",
   "metadata": {},
   "source": [
    "Ending up with 79 variables to explain 99% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.4) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72c68",
   "metadata": {},
   "source": [
    "Mention the logical sequence of steps taken to obtain the final model. \n",
    "\n",
    "- Neural Network Attempt no. 1\n",
    "- Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dd2cf",
   "metadata": {},
   "source": [
    "My first concern here was the feature selection. I was using neural networks to\n",
    "\n",
    "One of my first suggestions that came was to the model was to select the top couple of variables with respect to the correlation, but "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895b25b",
   "metadata": {},
   "source": [
    "# Single Neural Network Model using PCA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6aa1b",
   "metadata": {},
   "source": [
    "I got suspicions that the linear activation was performing suspiciously well, but I just kept trying neural network models to see if it could perform ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "effcde0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4403,)\n",
      "(4403, 79)\n",
      "(977,)\n",
      "(977, 79)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_pca, _ytrain, \n",
    "                                                    test_size=0.81829, random_state=36)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "800b2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_test_pca.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "ccd055e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 1.0961 - root_mean_squared_error: 1.0469\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.5929 - root_mean_squared_error: 0.7700\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.5180 - root_mean_squared_error: 0.7197\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.4680 - root_mean_squared_error: 0.6841\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.4272 - root_mean_squared_error: 0.6536\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.3903 - root_mean_squared_error: 0.6248\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.3513 - root_mean_squared_error: 0.5927\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.3236 - root_mean_squared_error: 0.5689\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 4s 21ms/step - loss: 0.2924 - root_mean_squared_error: 0.5408\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 3s 20ms/step - loss: 0.2771 - root_mean_squared_error: 0.5264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pca, _ytrain, \n",
    "                    epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "a02c8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step\n",
      "Root Mean Squared Error on Validation Set: 1.2761605820333004\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error on Validation Set:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "e60fe409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>2.074097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>2.059591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>1.228719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>0.953873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>0.652356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>1.354312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>1.727634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>2.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>1.601340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>1.477026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         0\n",
       "0     5380  2.074097\n",
       "1     5381  2.059591\n",
       "2     5382  1.228719\n",
       "3     5383  0.953873\n",
       "4     5384  0.652356\n",
       "...    ...       ...\n",
       "4398  9778  1.354312\n",
       "4399  9779  1.727634\n",
       "4400  9780  2.806687\n",
       "4401  9781  1.601340\n",
       "4402  9782  1.477026\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)\n",
    "to_merge = pd.DataFrame(y_pred)\n",
    "merge = pd.concat([true_test['id'], to_merge], axis = 1)\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "5638f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.columns =['id', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "f610a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['y'] = merge['y'].apply(lambda x: np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "2f3680bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>7.957357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>7.842758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>3.416849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>2.595744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>1.920058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>3.874095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>5.627323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>16.554986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>4.959676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>4.379902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          y\n",
       "0     5380   7.957357\n",
       "1     5381   7.842758\n",
       "2     5382   3.416849\n",
       "3     5383   2.595744\n",
       "4     5384   1.920058\n",
       "...    ...        ...\n",
       "4398  9778   3.874095\n",
       "4399  9779   5.627323\n",
       "4400  9780  16.554986\n",
       "4401  9781   4.959676\n",
       "4402  9782   4.379902\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = merge\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "0addad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.5) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6e03",
   "metadata": {},
   "source": [
    "Please provide details of the models/approaches you attempted but encountered challenges or unfavorable outcomes. If feasible, kindly explain the reasons behind their ineffectiveness or lack of success. Additionally, highlight the significant challenges or issues you encountered during the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b5675",
   "metadata": {},
   "source": [
    "I feel like I had a hard time with some feature selection models like KNN, random forest, and gradient boosting because they just took a long time with my data without great results. Once I thought about it theoritically, things like KNN made sense on why they didn't work, because the RMSE wasn't necessarily based opon the number of neighbors I had assigned. I could have used a technique like gridsearch to find the most optimal hyperparameters but I feel like having seen great results with Neural networks in my STAT 362 class, I could use that much more comfortably than other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7b917",
   "metadata": {},
   "source": [
    "## A.6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0af5e",
   "metadata": {},
   "source": [
    "* Do you feel that you gain valuable experience, skills, and/or knowledge? If yes, please explain what they were. If no, please explain.\n",
    "* What are things you liked/disliked about the project and/or work on the project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef17a01",
   "metadata": {},
   "source": [
    "I feel like I learned so many new important things about machine learning that I wouldn't have been able to express in any other way. I think learning with this dataset, with no strict linear or dimensional pattern has been very helpful to my understanding of data science and statistics in general. For example, I feel like data cleaning desicions were very hard to make, and a lot of the traditional data cleaning desicions I think we make on various kinds of datasets.\n",
    "\n",
    "I also feel like I was able to combine my knowledge from various classes from 303-3, 362, and other classes in a way that felt so real world for me, and in a way that made all the math and other statistical stuff I learned feel relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f42714",
   "metadata": {},
   "source": [
    "## Please make sure your github repo has all the code and  ensure that your code is capable of reproducing the outcomes you have submitted. It is important to avoid any form of academic misconduct or cheating by using your peer's submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
